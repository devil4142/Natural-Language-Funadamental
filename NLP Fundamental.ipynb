{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60f0eec-0293-4667-b356-879ecef633a1",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405ffde1-1ec4-4417-adcc-f23981c245f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nltk library \n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79d5c0c-658c-4b32-b306-cfde4b447daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'our nation faces a profound climate crisis that is impacting evvery Indian'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'our nation faces a profound climate crisis that is impacting evvery Indian'\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187f45ce-374e-41bf-a488-171e5cecd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are finding the words from the sentence \n",
    "\n",
    "def find_word(word, sentence):\n",
    "    return word in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed73640-932b-4cb2-a11f-fc08dcf97e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word('nation', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c016bc-eba3-42e1-9a37-5915595af788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word('indians', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc016c9-034b-4239-8db9-bdac6f30467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using index for finding the test position \n",
    "\n",
    "def get_index(word, text):\n",
    "    return text.index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5b821d-226d-4c0a-ae8e-ca63bf183df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index('crisis', sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ee8f37-700f-4da8-a88f-bfa8a5325a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(text, rank):\n",
    "    return text.split()[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ad4f25-1c11-4486-9b7a-50c706c59769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word(sentence, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7cabbb-e65a-496f-84b6-a19018b9f1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word(sentence, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80fcac7-7725-43a3-8832-7a8216cc1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'secaf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word(sentence, 2)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fefaeb-4f39-4e99-bb91-a15c7b653ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_words(text):\n",
    "    \"\"\"\n",
    "    This method will concat firstand last words of given text\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    print(words)\n",
    "\n",
    "    first_word = words[0]\n",
    "    print(first_word)\n",
    "\n",
    "    last_word = words[len(words)-1]\n",
    "    print(last_word)\n",
    "\n",
    "    return first_word + last_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad33002f-0704-4970-90d2-0b2df88f968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'nation', 'faces', 'a', 'profound', 'climate', 'crisis', 'that', 'is', 'impacting', 'evvery', 'Indian']\n",
      "our\n",
      "Indian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ourIndian'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_words(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8bba617-893f-4f5e-b5b6-b141065afa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_given_position_words(text):\n",
    "    words = text.split()\n",
    "    return [words[i] for i in range(len(words)) if i%2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72264a76-3431-4d61-b00f-cb47c83041fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our', 'faces', 'profound', 'crisis', 'is', 'evvery']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_given_position_words(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "458b48a6-2f20-45d7-8656-a8f890cad80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_letters(text, n):\n",
    "    return text[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e817a145-935a-4c36-8e07-c49f277f8a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ian'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_n_letters(sentence, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a381e021-3ff3-424e-90b7-c77edc29320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse(text):\n",
    "    return text[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bd89d16-2c42-4089-95de-5dadfbed373e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naidnI yrevve gnitcapmi si taht sisirc etamilc dnuoforp a secaf noitan ruo'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reverse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e54baf2e-4b2e-4bdd-98e2-0c79093ff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_reverse(text):\n",
    "    words = text.split()\n",
    "    return ''.join(word[::-1] for word in words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "186a1e16-75ba-4797-8c31-c4524439aa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ruonoitansecafadnuoforpetamilcsisirctahtsignitcapmiyrevvenaidnI'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_word_reverse(sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20ca2a-2839-4d6c-93a1-d29182a32f1c",
   "metadata": {},
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "raw",
   "id": "426e2ad8-e909-425b-a734-d48b94a50832",
   "metadata": {},
   "source": [
    "it is used to recognize the persons name or company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22f24b11-8df5-4d2c-8619-0e1653f4c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\AJAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\AJAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download \n",
    "from nltk import pos_tag \n",
    "from nltk import ne_chunk \n",
    "from nltk import word_tokenize\n",
    "download('maxent_ne_chunker')\n",
    "download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae4842e-43eb-4cec-862e-900d5342af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" we are reading a book published by Novels wihich is based out f Atlanta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63694bf-3022-4818-82c3-68b608e624c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(text):\n",
    "    i = ne_chunk(pos_tag(word_tokenize(text)), binary = True)\n",
    "    return[a for a in i if len(a)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "716144ab-9396-4634-a70d-72b13cd75097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('NE', [('Novels', 'NNP')])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ner(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2522c933-b77d-414e-ae26-4682dea525ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(text):\n",
    "    i = ne_chunk(pos_tag(word_tokenize(text)), binary = False)\n",
    "    return [a for a in i if len(a)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "880d71db-4a98-476f-8e34-6cdb0d513548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('PERSON', [('Novels', 'NNP')])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ner(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23096cec-1589-4c8a-867a-af7a1fe03546",
   "metadata": {},
   "source": [
    "# Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d02fd0ad-743d-4ab8-b213-a860982234ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd5b7586-9c56-499f-83e7-cb5f50b542e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b976e89-872a-49cd-9384-7c09c6d60f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'readin', 'NLP', 'fundamentals']\n"
     ]
    }
   ],
   "source": [
    "words = get_tokens(\"I am readin NLP fundamentals\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eb7712a-3652-4a87-a014-0def454b3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(words):\n",
    "    return pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1be77e71-49d0-4108-8639-4800a45322a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('readin', 'JJ'),\n",
       " ('NLP', 'NNP'),\n",
       " ('fundamentals', 'NNS')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a1803-6992-4f88-8769-f70427bbce1c",
   "metadata": {},
   "source": [
    "# spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f652a40d-deb3-4c4c-a364-1ae9c28fb874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Using cached autocorrect-2.6.1-py3-none-any.whl\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6c3fe10-bdd9-494e-90d2-8765ef0609d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5248a4e-05f1-486e-9bf6-d571ccd689f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell = Speller(lang='en') \n",
    "spell('Natureal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38871e66-0cd3-4d0e-95e9-01652ddb1ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'processin',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'the',\n",
       " 'art',\n",
       " 'of',\n",
       " 'extracting',\n",
       " 'insights',\n",
       " 'from',\n",
       " 'Natural',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Natural Language processin deal with the art of extracting insights from Natural Languages'\n",
    "sentence = word_tokenize(sentence) \n",
    "sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2867565-4725-40bd-9f58-a72946a939c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'processin', 'deal', 'with', 'the', 'art', 'of', 'extracting', 'insights', 'from', 'Natural', 'Languages']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "164f6429-f4ae-4bc2-a413-31bd7d87ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(tokens):\n",
    "    sentence_corrected = ' '.join([spell(word) for word in tokens])\n",
    "    return sentence_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42d937ee-b67d-4913-8f60-fb0dff6bb28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language processing deal with the art of extracting insights from Natural Languages\n"
     ]
    }
   ],
   "source": [
    "print(correct_spelling(sentence)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598270d-bf8a-436c-b3e6-9cb3bab4fa5d",
   "metadata": {},
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7d8b8a1-dc01-4772-a730-23bc0867a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07df69df-04cb-43df-aa6e-f5aa33c0078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stems(word, stemmer):\n",
    "    return stemmer.stem(word)\n",
    "porterstem = stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c324fab-5d71-4950-b6b6-bf283b584c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stems('production', porterstem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86a1f46b-c8a7-4da5-8ffd-fbec4a3fc095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stems('coming',porterstem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dd0775a-47ab-4813-9c05-1244e6b80c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stems('firing', porterstem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3b96b33-4869-4b15-a19f-f0e9e981c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'battl'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stems('battling', porterstem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21f5bfba-008a-4c0b-a013-9832c668ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7611e194-6b5e-46dd-8d91-f6fa693c2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'battl'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stem('battling', stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bb7af-7170-4f94-8bd9-24d1ce85f8e1",
   "metadata": {},
   "source": [
    "# stop word removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4b015eb-d225-4bbd-a9f1-7249173f1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AJAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import download \n",
    "download('stopwords') \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d439c690-f35d-4c49-97b0-172521943c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfc93e6b-ce38-48a5-88df-6d3d3f030ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c1ad868-e293-4b7a-a74e-666cb4effb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" I am a data scientst i have a knowledge of machine learning statistics and artifical intelligence\"\n",
    "sentence_words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "266da13f-5d53-446d-ba55-441ae3e287ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'a', 'data', 'scientst', 'i', 'have', 'a', 'knowledge', 'of', 'machine', 'learning', 'statistics', 'and', 'artifical', 'intelligence']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a9cb4fa-6889-4d15-9366-192226cfcb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence, stop_words):\n",
    "    return ' '.join([word for word in sentence if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2eed44f1-38b9-4df8-81b2-3c84faa4061a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I data scientst knowledge machine learning statistics artifical intelligence\n"
     ]
    }
   ],
   "source": [
    "print(remove_stop_words(sentence_words, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7861510-3cc7-4018-b601-6cf5f3afc690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data scientst knowledge machine statistics artifical intelligence\n"
     ]
    }
   ],
   "source": [
    "stop_words.extend(['I', 'It', 'one', 'learning', ',']) \n",
    "print(remove_stop_words(sentence_words, stop_words)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30c816-b763-480e-8e13-5c105af33210",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4228e84a-4577-4bfd-b9b4-6d9d970e257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I visiteed the US from the UK on 22-10-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb75ab81-bdff-4c6e-a7ed-b357ae78361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return text.replace('US', 'United States').replace('UK', 'United Kingdom').replace('18', '-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7026b9c-5da8-4549-8f9f-20bb6f1bd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I visiteed the United States from the United Kingdom on 22-10--2018\n"
     ]
    }
   ],
   "source": [
    "normalize_sentence = normalize(sentence) \n",
    "print(normalize_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2520f-3c6d-4051-b1c2-83cf426d7837",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a08d5d61-c916-42a5-9926-0244fdf7dfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AJAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "952dadb2-9879-40af-9c55-e99505e79080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11df7437-f3ec-4466-a5b8-7242b868ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AJAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0234fb13-c03d-4595-8078-a51bc9a897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(text):\n",
    "    words = text.split()\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1471831-1089-402d-b948-53d35d5e4799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'leaning', 'NLP', 'fundamentals.']\n"
     ]
    }
   ],
   "source": [
    "split_words(\"I am leaning NLP fundamentals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "308709e1-c3ec-44c4-9349-3d7abb852ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'leanring', 'NLP', 'funadamentals', '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokens(\"I am leanring NLP funadamentals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695435bc-6563-40a7-a201-3966f0717c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
